{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "f2b3d4c66a013cf1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load datasets\n",
    "players_df = pd.read_csv('./datasets/players.csv')\n",
    "teams_df = pd.read_csv('./datasets/teams.csv')\n",
    "\n",
    "# Preview the datasets\n",
    "print(\"Players Data Overview:\")\n",
    "print(players_df.info())\n",
    "print(players_df.head(), \"\\n\")\n",
    "\n",
    "print(\"Teams Data Overview:\")\n",
    "print(teams_df.info())\n",
    "print(teams_df.head(), \"\\n\")"
   ],
   "id": "8f474971a88b7ef8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensure uniqueness of teams in both datasets\n",
    "print(\"\\nUnique teams in Players Dataset:\", players_df['Team'].unique())\n",
    "print(\"Unique teams in Teams Dataset:\", teams_df['Team'].unique())\n",
    "\n",
    "# Check for duplicates and drop them\n",
    "print(\"\\nDuplicates in Players Dataset:\", players_df.duplicated().sum())\n",
    "print(\"Duplicates in Teams Dataset:\", teams_df.duplicated().sum())\n",
    "players_df = players_df.drop_duplicates()\n",
    "teams_df = teams_df.drop_duplicates()"
   ],
   "id": "12cb290d8a9e5263",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Missing values\n",
    "# print(\"\\nMissing Values in Players Dataset:\")\n",
    "# print(players_df.isnull().sum())\n",
    "# print(\"\\nMissing Values in Teams Dataset:\")\n",
    "# print(teams_df.isnull().sum())\n",
    "#\n",
    "# # Fill missing values (example: fill numeric with median, categorical with mode)\n",
    "# players_df.fillna(players_df.median(numeric_only=True), inplace=True)\n",
    "# teams_df.fillna(teams_df.median(numeric_only=True), inplace=True)\n",
    "# players_df.fillna(players_df.mode().iloc[0], inplace=True)\n",
    "# teams_df.fillna(teams_df.mode().iloc[0], inplace=True)"
   ],
   "id": "3c2da3a266373fe8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Merge datasets on the common column 'Team' \n",
    "combined_df = pd.merge(players_df, teams_df, on='Team', how='inner')\n",
    "print(\"\\nCombined Data Overview:\")\n",
    "print(combined_df.info())\n",
    "print(combined_df.head())\n",
    "\n",
    "# Descriptive Statistics\n",
    "print(\"\\nDescriptive Statistics for Players Data:\")\n",
    "print(players_df.describe())\n",
    "\n",
    "print(\"\\nDescriptive Statistics for Teams Data:\")\n",
    "print(teams_df.describe())"
   ],
   "id": "ff7b5caddad1c14c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Data Visualization\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Histogram of player points\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(players_df['PTS'], bins=20, kde=True, color='blue')\n",
    "plt.title('Distribution of Player Points')\n",
    "plt.xlabel('Points')\n",
    "plt.ylabel('Freq')\n",
    "plt.show()"
   ],
   "id": "26ce8f46e24553f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "teams_df.head()\n",
    "# Team vs Player points comparison\n",
    "team_points = teams_df[['Team', 'PTS']].set_index('Team')\n",
    "player_avg_points = players_df.groupby('Team')['PTS'].mean()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "team_points['Average Player Points'] = player_avg_points\n",
    "team_points.plot(kind='bar', figsize=(14, 7), title='Team vs Player Points Comparison')\n",
    "plt.ylabel('pts')\n",
    "plt.show()"
   ],
   "id": "462ebec5bda82e7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Correlation heatmap\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# corr = combined_df.corr()\n",
    "# sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
    "# plt.title('Correlation Heatmap')\n",
    "# plt.show()"
   ],
   "id": "3ab8105df8c917ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Outlier detection using IQR (detects points that are far or different from other points in the dataset)\n",
    "def detect_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "\n",
    "outliers = detect_outliers(players_df, 'PTS')\n",
    "print(\"\\nOutliers in Player Points:\")\n",
    "print(outliers)"
   ],
   "id": "73d4b02087c4e776",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save cleaned and processed data\n",
    "players_df.to_csv('./datasets/cleaned_players.csv', index=False)\n",
    "teams_df.to_csv('./datasets/cleaned_teams.csv', index=False)\n",
    "\n",
    "print(\"\\nEDA completed. Cleaned datasets saved!\")"
   ],
   "id": "4815772c711adccb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols_players = players_df.select_dtypes(include=['object']).columns\n",
    "categorical_cols_teams = teams_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(\"\\nCategorical Columns in Players Dataset:\", categorical_cols_players.tolist())\n",
    "print(\"Categorical Columns in Teams Dataset:\", categorical_cols_teams.tolist())\n",
    "\n",
    "# # Handle missing values in categorical columns (fill with mode)\n",
    "# for col in categorical_cols_players:\n",
    "#     players_df[col].fillna(players_df[col].mode()[0], inplace=True)\n",
    "# \n",
    "# for col in categorical_cols_teams:\n",
    "#     teams_df[col].fillna(teams_df[col].mode()[0], inplace=True)"
   ],
   "id": "c69947b5bb41f8c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Feature engineering: Create new features from categorical data (here convert team names to team codes)\n",
    "team_mapping = {name: idx for idx, name in enumerate(players_df['Team'].unique())}\n",
    "players_df['team_code'] = players_df['Team'].map(team_mapping)\n",
    "teams_df['team_code'] = teams_df['Team'].map(team_mapping)"
   ],
   "id": "85e4c13ef9797ed7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Encoding: Convert categorical variables into numerical formats using one-hot encoding technique\n",
    "players_encoded = pd.get_dummies(players_df, columns=['Name', 'Team'], prefix='pos', drop_first=True)\n",
    "teams_encoded = pd.get_dummies(teams_df, columns=['Team'], prefix='conf', drop_first=True)"
   ],
   "id": "68e14fda7787c578",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Scaling: Apply standardization for consistency (Scale player stats (excluding categorical/team_code))\n",
    "numerical_cols_players = players_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler_players = StandardScaler()\n",
    "players_df[numerical_cols_players] = scaler_players.fit_transform(players_df[numerical_cols_players])\n",
    "numerical_cols_teams = teams_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler_teams = StandardScaler()\n",
    "teams_df[numerical_cols_teams] = scaler_teams.fit_transform(teams_df[numerical_cols_teams])"
   ],
   "id": "12a945e637857a21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Final combined DataFrame for preprocessing\n",
    "final_combined_df = pd.merge(players_encoded, teams_encoded, on='team_code', how='inner')\n",
    "print(\"\\nPreprocessed Combined DataFrame Overview:\")\n",
    "print(final_combined_df.info())\n",
    "print(final_combined_df.head())\n",
    "final_combined_df.to_csv('./datasets/data.csv', index=False)"
   ],
   "id": "52aa2f6e19a195e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "preprocessing_steps = \"\"\"\n",
    "### Data Preprocessing Documentation\n",
    "\n",
    "#### 1. Raw Data Cleaning:\n",
    "- Dropped duplicate rows in both datasets.\n",
    "- Standardized column names to lowercase and stripped extra spaces.\n",
    "- Filled missing values:\n",
    "  - **Numeric columns**: Imputed using the median.\n",
    "  - **Categorical columns**: Imputed using the mode.\n",
    "\n",
    "#### 2. Handling Categorical Variables:\n",
    "- Identified categorical columns: 'team', 'position', and 'conference'.\n",
    "- Applied the following techniques:\n",
    "  - **Imputation**: Filled missing values with the most frequent value.\n",
    "  - **Feature Engineering**: Created a 'team_code' column by mapping team names to unique numeric codes.\n",
    "  - **Encoding**: One-hot encoded the 'position' (players) and 'conference' (teams) columns.\n",
    "\n",
    "#### 3. Scaling:\n",
    "- Standardized all numerical features using `StandardScaler` to ensure uniformity.\n",
    "\n",
    "#### 4. Data Merging:\n",
    "- Merged the players and teams datasets on the newly created 'team_code' column for seamless integration.\n",
    "\n",
    "#### 5. Final Dataset:\n",
    "- Saved the cleaned and processed datasets as 'cleaned_players.csv', 'cleaned_teams.csv', and 'final_combined.csv' for future use.\n",
    "\"\"\"\n",
    "\n",
    "# Save the preprocessing steps to a text file\n",
    "with open(\"preprocessing_documentation.txt\", \"w\") as file:\n",
    "    file.write(preprocessing_steps)\n",
    "\n",
    "print(\"\\nPreprocessing steps documented and saved to 'preprocessing_documentation.txt'.\")"
   ],
   "id": "bf42e7695aa387df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select features and target for regression (here predicting 'points' according to other features)\n",
    "X = players_df[['AST', 'REB', 'STL', 'BLK', 'TOV', 'Min', 'Age', 'GP', 'W', 'L', 'FG%']]\n",
    "y = players_df['PTS']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Initialize Linear Regression model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Fit model to training data\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Plot predicted vs actual points\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(y_test, y_pred, color='blue')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
    "plt.title('Linear Regression: Predicted vs Actual Points')\n",
    "plt.xlabel('Actual Points')\n",
    "plt.ylabel('Predicted Points')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ],
   "id": "7b40602721c3cdee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a binary classification target based on points (high vs low performance)\n",
    "median_points = players_df['PTS'].median()\n",
    "players_df['performance'] = (players_df['PTS'] >= median_points).astype(int)  # 1 for High, 0 for Low\n",
    "\n",
    "# Select features (excluding 'points' and 'performance')\n",
    "X_classify = players_df[['AST', 'REB', 'STL', 'BLK', 'TOV', 'Min', 'Age', 'GP', 'W', 'L', 'FG%']]\n",
    "y_classify = players_df['performance']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_classify, y_classify, test_size=0.2, random_state=42)\n",
    "# Initialize Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit model to training data\n",
    "clf.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_class = clf.predict(X_test_class)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_class, y_pred_class))\n",
    "\n",
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(12,8))\n",
    "tree.plot_tree(clf, feature_names=X_classify.columns, class_names=[\"Low\", \"High\"], filled=True, rounded=True)\n",
    "plt.title('Decision Tree Classifier for Player Performance')\n",
    "plt.show()"
   ],
   "id": "1c36e7af65dff50c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize ANN (MLP Classifier)\n",
    "ann_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "\n",
    "# Train the ANN model\n",
    "ann_clf.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_ann = ann_clf.predict(X_test_class)\n",
    "accuracy_ann = accuracy_score(y_test_class, y_pred_ann)\n",
    "\n",
    "print(f\"ANN Accuracy: {accuracy_ann}\")\n",
    "print(\"\\nANN Classification Report:\\n\", classification_report(y_test_class, y_pred_ann))"
   ],
   "id": "861d0868513ccc7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the confusion matrix for the classification model\n",
    "conf_matrix = confusion_matrix(y_test_class, y_pred_class)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[\"Low\", \"High\"])\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm_display.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Decision Tree / ANN Classifier\")\n",
    "plt.show()\n",
    "\n",
    "# Display classification accuracy\n",
    "accuracy_class = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f\"Accuracy: {accuracy_class}\")"
   ],
   "id": "96ae20d49621b5d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Predicted probabilities for each class\n",
    "y_pred_prob = ann_clf.predict_proba(X_test_class)\n",
    "\n",
    "# Plot predicted probabilities for the 'High' class\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(y_pred_prob[:, 1], bins=10, color='purple', alpha=0.7, label='Predicted Probability for High Performance')\n",
    "plt.title('Predicted Probabilities for High Performance')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "9d881a932ad9dd00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the regression model using MSE, RMSE, and R²\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R-squared (R²): {r2}\")\n",
    "# Evaluate the classification model\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "precision = precision_score(y_test_class, y_pred_class)\n",
    "recall = recall_score(y_test_class, y_pred_class)\n",
    "f1 = f1_score(y_test_class, y_pred_class)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_class, y_pred_class))"
   ],
   "id": "63435129478d9180",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the models using pkl\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "\n",
    "# Save the models using pickle\n",
    "with open('./models/ann_clf.pkl', 'wb') as file:\n",
    "    pickle.dump(ann_clf, file)\n",
    "\n",
    "with open('./models/ling_reg.pkl', 'wb') as file:\n",
    "    pickle.dump(lin_reg, file)\n",
    "\n",
    "with open('./models/clf.pkl', 'wb') as file:\n",
    "    pickle.dump(clf, file)  "
   ],
   "id": "853132c1b22e5963",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
