#%%
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeClassifier
import warnings
warnings.filterwarnings('ignore')
#%%
# Load datasets
players_file = "players.csv"
team_file = "team.csv"

players_df = pd.read_csv(players_file)
team_df = pd.read_csv(team_file)
#%%
# Data Cleaning
def clean_data(df, df_name):
    print(f"Cleaning {df_name}...")
    # Check for duplicates
    duplicates = df.duplicated().sum()
    print(f"Duplicates in {df_name}: {duplicates}")
    if duplicates > 0:
        df = df.drop_duplicates()

    # Check for null values
    nulls = df.isnull().sum()
    print(f"Null values in {df_name}:\n{nulls[nulls > 0]}")

    # Drop columns with >50% null values
    threshold = 0.5 * len(df)
    df = df.dropna(axis=1, thresh=threshold)
    return df

# Cleaning both datasets
players_cleaned = clean_data(players_df, "players_df")
team_cleaned = clean_data(team_df, "team_df")
#%%
# Merging datasets on 'Team'
merged_df = pd.merge(players_cleaned, team_cleaned, on='Team', how='inner')

# Drop remaining null columns before visualizations
merged_df = merged_df.dropna(axis=1)

# Descriptive Statistics
desc_stats = merged_df.describe()
print("Descriptive Statistics:\n", desc_stats)
#%%
# Data Visualization
# Distribution of points per game (PTS)
plt.figure(figsize=(8, 6))
sns.histplot(players_cleaned['PTS'], kde=True, bins=20, color='blue')
plt.title("Distribution of Points Per Game (PTS)")
plt.xlabel("PTS")
plt.ylabel("Frequency")
plt.show()
#%%
# Correlation Heatmap
plt.figure(figsize=(12, 8))

# Select only numeric columns for correlation
numeric_df = merged_df.select_dtypes(include=['number'])
correlation = numeric_df.corr()

# Plot the heatmap
sns.heatmap(correlation, annot=True, fmt=".2f", cmap="coolwarm", cbar=True)
plt.title("Correlation Heatmap")
plt.show()
#%%
# Handle missing values
imputer = SimpleImputer(strategy="mean")
numeric_columns = merged_df.select_dtypes(include=['number']).columns
merged_df[numeric_columns] = imputer.fit_transform(merged_df[numeric_columns])

# Detect and handle outliers using the IQR method
numeric_df = merged_df[numeric_columns]

Q1 = numeric_df.quantile(0.25)
Q3 = numeric_df.quantile(0.75)
IQR = Q3 - Q1

# Filter rows to exclude outliers
outliers_removed_df = merged_df[~((numeric_df < (Q1 - 1.5 * IQR)) | (numeric_df > (Q3 + 1.5 * IQR))).any(axis=1)]
#%%
# Identify categorical columns
categorical_cols = merged_df.select_dtypes(include=['object']).columns

# Fill missing values in categorical columns
merged_df[categorical_cols] = merged_df[categorical_cols].fillna('Missing')

# One-hot encode categorical variables
encoder = OneHotEncoder(drop="first", sparse_output=False)
encoded_categories = pd.DataFrame(
    encoder.fit_transform(merged_df[categorical_cols]),
    columns=encoder.get_feature_names_out(categorical_cols)
)

# Concatenate encoded categorical variables with the rest of the dataset
processed_df = pd.concat(
    [merged_df.drop(categorical_cols, axis=1).reset_index(drop=True),
     encoded_categories.reset_index(drop=True)],
    axis=1
)

# Scale numerical data
scaler = StandardScaler()
numerical_cols = processed_df.select_dtypes(include=['number']).columns
processed_df[numerical_cols] = scaler.fit_transform(processed_df[numerical_cols])
#%%
# Visualize correlation heatmap for processed data
# plt.figure(figsize=(12, 8))
numeric_df = processed_df.select_dtypes(include=['number'])
# correlation = numeric_df.corr()
# sns.heatmap(correlation, annot=True, fmt=".2f", cmap="coolwarm", cbar=True)
# plt.title("Correlation Heatmap (Processed Data)")
# plt.show()

# Final statistics
print("Descriptive Statistics:")
print(processed_df.describe())
#%%
# Predicting the efficiency of the players
if 'Efficiency' not in processed_df.columns:
    processed_df['Efficiency'] = np.random.rand(len(processed_df))  

X = processed_df.drop('Efficiency', axis=1)
y = processed_df['Efficiency']

# Splitting the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Applying Linear Regression
regressor = LinearRegression()
regressor.fit(X_train, y_train)

# Predictions
y_pred = regressor.predict(X_test)

# Evaluation
print("Regression Metrics:")
print(f"Mean Squared Error: {mean_squared_error(y_test, y_pred):.4f}")
print(f"R2 Score: {r2_score(y_test, y_pred):.4f}")
#%%
# Classify players as Bad, Average, or Good
if 'Player Class' not in processed_df.columns:
    bins = [-np.inf, -0.5, 0.5, np.inf]
    labels = ['Bad', 'Average', 'Good']
    processed_df['Player Class'] = pd.cut(processed_df['Efficiency'], bins=bins, labels=labels)

X = processed_df.drop(['Player Class', 'Efficiency'], axis=1)
y = processed_df['Player Class']

# Splitting the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Applying Decision Tree Classifier
classifier = DecisionTreeClassifier(random_state=42)
classifier.fit(X_train, y_train)

# Predictions
y_pred = classifier.predict(X_test)

# Evaluation
print("Classification Metrics:")
print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
print("Classification Report:")
print(classification_report(y_test, y_pred))
#%%
# Apply the trained classifier to predict classes for all players
merged_df['Predicted Class'] = classifier.predict(X)
print(merged_df[['Player', 'Predicted Class']].head())