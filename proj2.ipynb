{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "5e538558c352b6bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "players_file = \"./datasets/players.csv\"\n",
    "team_file = \"./datasets/team.csv\"\n",
    "\n",
    "players_df = pd.read_csv(players_file)\n",
    "team_df = pd.read_csv(team_file)"
   ],
   "id": "f259452e8f7ca707",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clean_data(df, df_name):\n",
    "    print(f\"Cleaning {df_name}...\")\n",
    "    # Check for duplicates\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"Duplicates in {df_name}: {duplicates}\")\n",
    "    if duplicates > 0:\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "    # Check for null values\n",
    "    nulls = df.isnull().sum()\n",
    "    print(f\"Null values in {df_name}:\\n{nulls[nulls > 0]}\")\n",
    "\n",
    "    threshold = 0.5 * len(df)\n",
    "    df = df.dropna(axis=1, thresh=threshold)  # Drop columns with too many null values\n",
    "\n",
    "    # Drop any remaining columns that are fully null\n",
    "    df = df.dropna(axis=1, how='all')  # Drop columns where all values are null\n",
    "\n",
    "    # Impute missing values\n",
    "    df = impute_missing_values(df)\n",
    "\n",
    "    return df"
   ],
   "id": "56e3e41a4704b016",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Improved missing value handling\n",
    "def impute_missing_values(df):\n",
    "    # Numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    df[numeric_cols] = KNNImputer(n_neighbors=5).fit_transform(df[numeric_cols])  # Using KNN imputer\n",
    "\n",
    "    # Categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    df[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])  # Most frequent imputation\n",
    "    return df\n",
    "\n",
    "# Cleaning both datasets\n",
    "players_cleaned = clean_data(players_df, \"players_df\")\n",
    "team_cleaned = clean_data(team_df, \"team_df\")"
   ],
   "id": "1e0cab4e7625f8ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Merging datasets on 'Team'\n",
    "merged_df = pd.merge(players_cleaned, team_cleaned, on='Team', how='inner')\n",
    "\n",
    "# Drop remaining null columns before visualizations\n",
    "merged_df = merged_df.dropna(axis=1)\n",
    "\n",
    "# Descriptive Statistics\n",
    "desc_stats = merged_df.describe()\n",
    "print(\"Descriptive Statistics:\\n\", desc_stats)"
   ],
   "id": "bd43a8881b2e927",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Data Visualization\n",
    "# Distribution of points per game (PTS)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(players_cleaned['PTS'], kde=True, bins=20, color='blue')\n",
    "plt.title(\"Distribution of Points Per Game (PTS)\")\n",
    "plt.xlabel(\"PTS\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ],
   "id": "5b0bdb979fee27de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "numeric_df = merged_df.select_dtypes(include=['number'])\n",
    "correlation = numeric_df.corr()\n",
    "sns.heatmap(correlation, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ],
   "id": "326dd0f3d6b9867b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "merged_df.head()",
   "id": "1b97f50be54dfed3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create new features based on domain knowledge\n",
    "merged_df['Points_Per_Minute'] = merged_df['PTS_x'] / merged_df['Min_x']\n",
    "merged_df['Assist_to_Turnover_Ratio'] = merged_df['AST_x'] / merged_df['TOV_x']\n",
    "\n",
    "# Scaling data with RobustScaler (alternative to StandardScaler)\n",
    "scaler = RobustScaler()\n",
    "numerical_cols = merged_df.select_dtypes(include=['number']).columns\n",
    "merged_df[numerical_cols] = scaler.fit_transform(merged_df[numerical_cols])\n",
    "\n",
    "# One-Hot Encoding for Categorical Data\n",
    "encoder = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
    "categorical_cols = merged_df.select_dtypes(include=['object']).columns\n",
    "encoded_categories = pd.DataFrame(\n",
    "    encoder.fit_transform(merged_df[categorical_cols]),\n",
    "    columns=encoder.get_feature_names_out(categorical_cols)\n",
    ")"
   ],
   "id": "49a42c0b31659f2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Concatenate encoded categorical variables with the rest of the dataset\n",
    "processed_df = pd.concat([merged_df.drop(categorical_cols, axis=1).reset_index(drop=True),\n",
    "                          encoded_categories.reset_index(drop=True)], axis=1)\n",
    "\n",
    "if 'Efficiency' not in processed_df.columns:\n",
    "    processed_df['Efficiency'] = np.random.rand(len(processed_df))\n",
    "\n",
    "X = processed_df.drop('Efficiency', axis=1)\n",
    "y = processed_df['Efficiency']\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply Linear Regression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = regressor.predict(X_test)"
   ],
   "id": "af73dddec8fe1d3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluation\n",
    "print(\"Regression Metrics:\")\n",
    "print(f\"Mean Squared Error: {mean_squared_error(y_test, y_pred):.4f}\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "if 'Player Class' not in processed_df.columns:\n",
    "    bins = [-np.inf, -0.5, 0.5, np.inf]\n",
    "    labels = ['Bad', 'Average', 'Good']\n",
    "    processed_df['Player Class'] = pd.cut(processed_df['Efficiency'], bins=bins, labels=labels)\n",
    "\n",
    "X = processed_df.drop(['Player Class', 'Efficiency'], axis=1)\n",
    "y = processed_df['Player Class']\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply Decision Tree Classifier\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = classifier.predict(X_test)"
   ],
   "id": "fa8d950e6f908229",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluation\n",
    "print(\"Classification Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "id": "19e9e1e850fe95d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Hyperparameter Tuning with GridSearchCV for Decision Tree\n",
    "param_grid = {'max_depth': [5, 10, 15, None], 'min_samples_split': [2, 5, 10]}\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Hyperparameters for Decision Tree Classifier:\", grid_search.best_params_)\n",
    "# Retrain with best parameters\n",
    "best_classifier = grid_search.best_estimator_\n",
    "y_pred_best = best_classifier.predict(X_test)"
   ],
   "id": "bce14de6bd76e891",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluation after hyperparameter tuning\n",
    "print(\"Classification Metrics (after tuning):\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_best):.4f}\")\n",
    "print(\"Classification Report (after tuning):\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "merged_df['Predicted Class'] = best_classifier.predict(X)\n",
    "print(merged_df[['Player', 'Predicted Class']].head())\n",
    "\n",
    "# Save models for future use\n",
    "joblib.dump(regressor, './models/regressor_model.pkl')\n",
    "joblib.dump(best_classifier, './modelsclassifier_model.pkl')\n",
    "merged_df.to_csv('./datasets/merged.csv')"
   ],
   "id": "c5fe4c227ec63a38",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
